{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Thesis_Notebook_v4_3ClassesCrossValidation_Versione in consegna.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wmex91/Intelligent-Poka-Yoke/blob/main/DL_Thesis_Notebook_v4_3ClassesCrossValidation_Versione_in_consegna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CARICO GDRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvUINRv0lHJ_",
        "outputId": "f323170b-bc19-4a8f-e1fd-3e9817974067"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MODELLO DI ADDESTRAMENTO - YES CONFUSION MATRIX, NO DATA AUGMENTATION, YES TENSORBOARD \n",
        "#3 CLASSI, SI CROSS VALIDATION\n",
        "\n",
        "#!pip install tensorboardcolab\n",
        "\n",
        "from numpy.random import seed\n",
        "#Random seed per Numpy\n",
        "seed(1)\n",
        "\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# from tensorflow import set_random_seed\n",
        "# import keras.datasets\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from skimage import io \n",
        "import random \n",
        "# from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "import time"
      ],
      "metadata": {
        "id": "6PkGV3Y9i9X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNZIONI E METODI ############################################################\n",
        "\n",
        "#Imposto una funzione per caricare i dati dalle directory di partenza\n",
        "def loading_data(directory, sbatch, filter_type):\n",
        "  for category in labels:  # itero tra OK, rOK e vOK\n",
        "\n",
        "    path = os.path.join(directory, category)  # crea il percorso per OK, rOK e vOK\n",
        "    class_num = labels.index(category)  # Imposta la classificazione \n",
        "\n",
        "    for img in tqdm(os.listdir(path)):  # itera ogni immagine per OK, rOK e vOK\n",
        "          img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) # converte in array\n",
        "          \n",
        "          if filter_type == 0: \n",
        "            sbatch.append([img_array, class_num]) \n",
        "          \n",
        "          if filter_type == 1: \n",
        "            filtered_image = gaussian_filter(img_array)\n",
        "            sbatch.append([filtered_image, class_num])  # aggiunge a training_set; se faccio resize, aggiungo resize_array\n",
        "          \n",
        "          if filter_type == 2:\n",
        "            filtered_image = filter_5x5(img_array)\n",
        "            sbatch.append([filtered_image, class_num])  # aggiunge a training_set; se faccio resize, aggiungo resize_array\n",
        "          \n",
        "          if filter_type == 3:\n",
        "            filtered_image = filter_3x3(img_array)\n",
        "            sbatch.append([filtered_image, class_num]) \n",
        "          \n",
        "          #resize_array = cv2.resize(img_array, (64, 64))  # resize \n",
        "          \n",
        "          #plt.imshow(filtered_image, cmap='gray') # grafica\n",
        "          #plt.show()  # mostra\n",
        "          \n",
        "          #break\n",
        "    #break\n",
        "    \n",
        "#Funzione filtro passa alto piccolo \n",
        "def filter_3x3(data):\n",
        "  kernel_3x3 = np.array([[-1, -1, -1],\n",
        "                     [-1,  8, -1],\n",
        "                     [-1, -1, -1]])\n",
        "  highpass_3x3 = ndimage.convolve(data, kernel_3x3)\n",
        "\n",
        "#Funzione filtro passa alto grande\n",
        "def filter_5x5(data):\n",
        "  kernel_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
        "                   [-1,  1,  2,  1, -1],\n",
        "                   [-1,  2,  4,  2, -1],\n",
        "                   [-1,  1,  2,  1, -1],\n",
        "                   [-1, -1, -1, -1, -1]])    \n",
        "  highpass_5x5 = ndimage.convolve(data, kernel_5x5)\n",
        "  return(highpass_5x5)\n",
        "\n",
        "#Fuzione filtro Gaussiano \n",
        "def gaussian_filter(data):\n",
        "  gaussian_lowpass = ndimage.gaussian_filter(data, 3)\n",
        "  gaussian_highpass = img_array - img_gaussian_lowpass\n",
        "  return(gaussian_highpass)\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "Uk3xl6E1jCec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels.index('OK'))\n",
        "print(labels.index('rOK'))\n",
        "print(labels.index('vOK'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ddq25VPlDeGM",
        "outputId": "2fd91d0b-33e9-4935-ce9e-77c905eb4c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-55d563928cdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rOK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vOK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "# INIZIALIZZO GLI STRUMENTI IN USO NEL PROGRAMMA ###############################\n",
        "\n",
        "#Pulisco la sessione dai dati settati in precedenza\n",
        "K.clear_session()\n",
        "\n",
        "#Random seed per Tensorflow\n",
        "#set_random_seed(2)\n",
        "tf.random.set_seed(2)\n",
        "#Imposto una funzione per salvare il modello senza sovrascriverlo ai precedenti\n",
        "nome = \"MasterThesis-cnn-3classes-TB-nDA_\" + str(time.localtime().tm_mday) + \".\" + str(time.localtime().tm_mon) + \".\" + str(time.localtime().tm_year) + \"_\"  + str(time.localtime().tm_hour+2) + \":\"  + str(time.localtime().tm_min)\n",
        "\n",
        "#Imposto l'oggetto tbc come TensorBoard per visualizzare i grafici di output \n",
        "#tbc = TensorBoardColab()\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "4WoP0ROwjFx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CARICAMENTO DATI #############################################################\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/Master-Thesis-Project/dataset/240x320/3_classes_K-FoldValidation'\n",
        "          \n",
        "#validation_data_dir = '/content/drive/My Drive/Colab Notebooks/dataset/240x320/2_classes/2 Classes_2 States/validation_set'\n",
        "\n",
        "img_width, img_height = 320, 240\n",
        "labels = [\"OK\", \"rOK\", \"vOK\"] # OK=dritto, rOK=rovescio, vOK=assente\n",
        "\n",
        "#Preparo gli array per il caricamento dati\n",
        "data_set = []\n",
        "\n",
        "#Richiamo la funzione di caricamento dati\n",
        "loading_data(data_dir, data_set, 2)\n",
        "\n",
        "print(\"\\nlunghezza data set: \" + str(len(data_set)))\n",
        "\n",
        "#Imposto un seed per lo shuffle e mescolo il data set in quanto i dati caricati sono ordinati per classe\n",
        "random.seed(4)\n",
        "random.shuffle(data_set)\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncW57r18jK7q",
        "outputId": "c64c5944-94fe-4f19-ad59-11edd576952a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:04<00:00, 33.06it/s]\n",
            "100%|██████████| 150/150 [00:05<00:00, 27.34it/s]\n",
            "100%|██████████| 201/201 [00:05<00:00, 33.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lunghezza data set: 501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIVISIONE DATA SET IN 5 SUBSET ###############################################\n",
        "\n",
        "#Imposto 5 array di arrivo\n",
        "sub_set1 = []\n",
        "sub_set2 = []\n",
        "sub_set3 = []\n",
        "sub_set4 = []\n",
        "sub_set5 = []\n",
        "\n",
        "#LI DEVO MESCOLARE PRIMA DI INSERIRLI NEL T.SUBSET? O LI MESCOLO A OGNI ITERAZIONE K-ESIMA?\n",
        "\n",
        "#Divido il dataset in 5 parti e assegno ogni parte al relativo subset\n",
        "for i in range (len(data_set)):\n",
        "  if i < 100: \n",
        "    sub_set1.append(data_set[i])\n",
        "  elif i >= 100 and i < 200:\n",
        "    sub_set2.append(data_set[i])\n",
        "  elif i >= 200 and i < 300: \n",
        "    sub_set3.append(data_set[i])\n",
        "  elif i >= 300 and i < 400: \n",
        "    sub_set4.append(data_set[i])\n",
        "  elif i >= 400: \n",
        "    sub_set5.append(data_set[i])\n",
        "\n",
        "print(\"lunghezza subset1: \" + str(len(sub_set1)))\n",
        "print(\"lunghezza subset2: \" + str(len(sub_set2)))\n",
        "print(\"lunghezza subset3: \" + str(len(sub_set3)))\n",
        "print(\"lunghezza subset4: \" + str(len(sub_set4)))\n",
        "print(\"lunghezza subset5: \" + str(len(sub_set5)))\n",
        "    \n",
        "#Raccolgo tutti i subset in un array, per comodità \n",
        "t_subs = []\n",
        "t_subs.append(sub_set1)\n",
        "t_subs.append(sub_set2)\n",
        "t_subs.append(sub_set3)\n",
        "t_subs.append(sub_set4)\n",
        "t_subs.append(sub_set5)\n",
        "\n",
        "print(\"lunghezza t_subs: \")\n",
        "print(len(t_subs))\n",
        "print(\"\")\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "SeIaAtEKjQqH",
        "outputId": "15af712d-b611-4ddd-d334-15db16b8453f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3533eb0dddb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Divido il dataset in 5 parti e assegno ogni parte al relativo subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msub_set1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQjNvpAFG7OM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "40325cbb-0f5c-4009-c6c0-365b897a72ca"
      },
      "source": [
        "# INIZIALIZZAZIONE STRUTTURE DATI PER CROSS VALIDATION #########################\n",
        "\n",
        "#Inizializzo l'array contente i risultati della Cross Validation\n",
        "k_fold_conf_matrix = []\n",
        "k_fold_accuracies = []\n",
        "k_fold_precisions_ClassOK = []\n",
        "\n",
        "################################################################################\n",
        "\n",
        "# INIZIO CROSS VALIDATION ######################################################\n",
        "\n",
        "for i in range(0, 5):\n",
        "  #Inizia QUA il ciclo for per le 5 fasi di training\n",
        "  #Inizializzo dei nuovi array per training, validation e test set; alla fine del ciclo, resetto i valori modificati\n",
        "  training_set = []\n",
        "  validation_set = []\n",
        "  test_set = []\n",
        "\n",
        "  #Assegno i subset generati ai vettore di training, validation e test a seconda del ciclo k a cui mi trovo \n",
        "  if i == 0: # test=0; validation=1\n",
        "    for j in range(len(t_subs[0])):\n",
        "      test_set.append(t_subs[0][j])\n",
        "    for j in range(len(t_subs[1])):\n",
        "      validation_set.append(t_subs[1][j])\n",
        "    for j in range(len(t_subs[2])):\n",
        "      training_set.append(t_subs[2][j])\n",
        "    for j in range(len(t_subs[3])):\n",
        "      training_set.append(t_subs[3][j])\n",
        "    for j in range(len(t_subs[4])):\n",
        "      training_set.append(t_subs[4][j])\n",
        "        \n",
        "  if i == 1: #test=1; validation=2\n",
        "    for j in range(len(t_subs[1])):\n",
        "      test_set.append(t_subs[1][j])\n",
        "    for j in range(len(t_subs[2])):\n",
        "      validation_set.append(t_subs[2][j])\n",
        "    for j in range(len(t_subs[3])):\n",
        "      training_set.append(t_subs[3][j])\n",
        "    for j in range(len(t_subs[4])):\n",
        "      training_set.append(t_subs[4][j])\n",
        "    for j in range(len(t_subs[0])):\n",
        "      training_set.append(t_subs[0][j])    \n",
        "  \n",
        "  if i == 2: #test=2; validation=3\n",
        "    for j in range(len(t_subs[2])):\n",
        "      test_set.append(t_subs[2][j])\n",
        "    for j in range(len(t_subs[3])):\n",
        "      validation_set.append(t_subs[3][j])\n",
        "    for j in range(len(t_subs[4])):\n",
        "      training_set.append(t_subs[4][j])\n",
        "    for j in range(len(t_subs[0])):\n",
        "      training_set.append(t_subs[0][j])\n",
        "    for j in range(len(t_subs[1])):\n",
        "      training_set.append(t_subs[1][j])\n",
        "  \n",
        "  if i == 3: #test=3; validation=4\n",
        "    for j in range(len(t_subs[3])):\n",
        "      test_set.append(t_subs[3][j])\n",
        "    for j in range(len(t_subs[4])):\n",
        "      validation_set.append(t_subs[4][j])\n",
        "    for j in range(len(t_subs[0])):\n",
        "      training_set.append(t_subs[0][j])\n",
        "    for j in range(len(t_subs[1])):\n",
        "      training_set.append(t_subs[1][j])\n",
        "    for j in range(len(t_subs[2])):\n",
        "      training_set.append(t_subs[2][j])\n",
        "  \n",
        "  if i == 4: #test=4; validation=0\n",
        "    for j in range(len(t_subs[4])):\n",
        "      test_set.append(t_subs[4][j])\n",
        "    for j in range(len(t_subs[0])):\n",
        "      validation_set.append(t_subs[0][j])\n",
        "    for j in range(len(t_subs[1])):\n",
        "      training_set.append(t_subs[1][j])\n",
        "    for j in range(len(t_subs[2])):\n",
        "      training_set.append(t_subs[2][j])\n",
        "    for j in range(len(t_subs[3])):\n",
        "      training_set.append(t_subs[3][j])\n",
        "\n",
        "  print(\"lunghezza training, validation e test set\")\n",
        "  print(len(training_set))\n",
        "  print(len(validation_set))\n",
        "  print(len(test_set))\n",
        "        \n",
        "  #Preprocessing training set \n",
        "  #Popolo il vettore delle train feature e delle train target\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for features, label in training_set:\n",
        "      X_train.append(features)\n",
        "      y_train.append(label)\n",
        "\n",
        "  X_train = np.array(X_train).reshape(-1, img_width, img_height, 1)\n",
        "\n",
        "  #Normalizzazione dei dati \n",
        "  X_train = X_train/255.0\n",
        "\n",
        "  #Imposto il vettore dei target in 3 categorie\n",
        "  y_train_3 = to_categorical(y_train, 3)\n",
        "\n",
        "  #Preprocessing validation set\n",
        "  #Popolo il vettore delle validaiton feature e delle validation target\n",
        "  X_validation = []\n",
        "  y_validation = []\n",
        "\n",
        "  for features,label in validation_set:\n",
        "      X_validation.append(features)\n",
        "      y_validation.append(label)\n",
        "\n",
        "  X_validation = np.array(X_validation).reshape(-1, img_width, img_height, 1)\n",
        "\n",
        "  # Normalizzazione dei dati \n",
        "  X_validaiton = X_validation/255.0\n",
        "  \n",
        "  #Imposto il vettore dei target in 3 categorie\n",
        "  y_validation_3 = to_categorical(y_validation, 3)\n",
        "  \n",
        "  #Preprocessing test set\n",
        "  # Popolo il vettore delle test feature e delle test target\n",
        "  X_test = []\n",
        "  y_test = []\n",
        "\n",
        "  for features,label in test_set:\n",
        "      X_test.append(features)\n",
        "      y_test.append(label)\n",
        "\n",
        "  X_test = np.array(X_test).reshape(-1, img_width, img_height, 1)\n",
        "\n",
        "  # Normalizzazione dei dati \n",
        "  X_test = X_test/255.0\n",
        "\n",
        "  # Imposto il vettore dei target in 3 categorie\n",
        "  y_test_3 = to_categorical(y_test, 3)\n",
        "  \n",
        "  print(\"Dimensione validation set dopo labeling: \" + str(len(y_validation_3)))\n",
        "  print(\"\")\n",
        "        \n",
        "  print(\"K-Fold Cross Validation con k = \" + str(i))\n",
        "\n",
        "  ##############################################################################\n",
        "  \n",
        "  # INIZIO MODELLO RETE NEURALE ################################################\n",
        "  #Pulizia da modelli precedentemente addestrati\n",
        "  K.clear_session()\n",
        "  \n",
        "  # Initialize the CNN\n",
        "  classifier = Sequential()\n",
        "\n",
        "  # Step 1 - Convolution - Commentato lo strato standard\n",
        "  classifier.add(Convolution2D(filters=32, kernel_size=3, input_shape=X_train.shape[1:], padding='same', activation='relu'))\n",
        "\n",
        "  # Step 2 - Pooling\n",
        "  classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Step 3 - Flattening - Srotolo la matrice in output ai filtri come un'unico vettore\n",
        "  classifier.add(Flatten())\n",
        "\n",
        "  classifier.add(Dense(64, activation='relu'))\n",
        "\n",
        "  # Step 4 - Strato di Dropout - Per ridurre l'overfitting; da testare in seguito\n",
        "  classifier.add(Dropout(0.5))\n",
        "\n",
        "  # Step 5 - Imposto l'output layer\n",
        "  classifier.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  # Imposto esplicitamente l'ottimizzatore per alzare il learning rate\n",
        "  # optimizer_set = optimizers.Adam(lr=0.1)\n",
        "\n",
        "  # Step 6 - Compilazione della CNN\n",
        "  classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # Step 7 - Implemento l'early stopping per diminuire l'overfitting\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "\n",
        "  # Step 8 - Addestramento della CNN\n",
        "  classifier.fit(X_train, y_train_3, batch_size=32, epochs=500, validation_data=(X_validation, y_validation_3), callbacks=[es])\n",
        "\n",
        "  # Salva il modello; posso salvare i pesi (.model extension) o l'intero modello (.h5 extension)\n",
        "  # Per richiamare il modello salvato: new_model = keras.models.load_model('my_model.h5')\n",
        "  # Vedi in => https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_restore_models.ipynb#scrollTo=5NDMO_7kS6Do\n",
        "  # classifier.save_weights('/content/drive/My Drive/Colab Notebooks/PhD_Notebooks/Master-Thesis-Project/dataset/model_saved/' + nome + '.h5')\n",
        "\n",
        "  ################################################################################\n",
        "\n",
        "  # FASE DI PREDIZIONE E VALUTAZIONE PRESTAZIONI #################################\n",
        "\n",
        "  #Effettuo la predizione del test set \n",
        "  predizione_no_cutoff = classifier.predict(X_test)\n",
        "\n",
        "  # Converto i valori predetti in virgola in interi: 0 non predetto, 1 predetto. La posizione nel vettore indica lo stato predetto\n",
        "  predizione_cutoff_no_labels = []\n",
        "\n",
        "  for index in range(len(predizione_no_cutoff)): \n",
        "    min = 0\n",
        "    z = -1\n",
        "    for value in range(0,3): \n",
        "      if predizione_no_cutoff[index][value] > min:\n",
        "        min = predizione_no_cutoff[index][value]\n",
        "        z = value\n",
        "    #test_risultato[index][z] = 1\n",
        "\n",
        "    conversione = []\n",
        "    for valuetest in range(0,3): \n",
        "      if valuetest == z:\n",
        "        conversione.append(1)\n",
        "      else: \n",
        "        conversione.append(0)\n",
        "\n",
        "    predizione_cutoff_no_labels.append(conversione)\n",
        "\n",
        "  # Converto i valori predetti da binari in valori di labels: stato 1 = 0, stato 2 = 1, stato 3 = 2\n",
        "  predizione_labels = []\n",
        "  for index1 in range(len(y_test_3)):\n",
        "    x = -1\n",
        "    for index2 in range(0,3):\n",
        "      if predizione_cutoff_no_labels[index1][index2] == 1: \n",
        "        x = index2\n",
        "    predizione_labels.append(x)\n",
        "  \n",
        "  # Converto i valori di test in posizione in valori di labels: stato 1 = 0, stato 2 = 1, stato 3 = 2\n",
        "  y_test_3_labels = []\n",
        "\n",
        "  for index1 in range(len(y_test_3)):\n",
        "    y = -1\n",
        "    for index2 in range(0,3):\n",
        "      if y_test_3[index1][index2] == 1: \n",
        "        y = index2\n",
        "    y_test_3_labels.append(y)\n",
        "\n",
        "  #Converto gli array predetti ed esatti in numpy.array per la matrice di confusione di Scikit Learn\n",
        "  y_test_3_labels = np.array(y_test_3_labels)\n",
        "  predizione_labels = np.array(predizione_labels)\n",
        "\n",
        "  if i == 0: \n",
        "    # Definisco la matrice di confusione per k-fold=0\n",
        "    confusion_matrix0 = confusion_matrix(y_test_3_labels, predizione_labels, labels=[0, 1, 2])\n",
        "    # Aggiungo la matrice di confusione al vettore k_fold_conf_matrix\n",
        "    k_fold_conf_matrix.append(confusion_matrix0)\n",
        "    # Stampo la matrice di confusione\n",
        "    print(\"Matrice di confusione\")\n",
        "    print(confusion_matrix0)\n",
        "    # Computo accuratezza, precisione OK/rOK, false_positive_rate rOK\n",
        "    accuratezza = (confusion_matrix0[0][0] + confusion_matrix0[1][1] + confusion_matrix0[2][2])/(len(y_test_3_labels))\n",
        "    precisione_OK = (confusion_matrix0[0][0])/(confusion_matrix0[0][0] + confusion_matrix0[0][1] + confusion_matrix0[0][2])\n",
        "      \n",
        "    false_pos_rate_rOK = (confusion_matrix0[1][0] + confusion_matrix0[1][2])/(confusion_matrix0[1][0] + confusion_matrix0[1][2] + confusion_matrix0[0][0] + confusion_matrix0[2][2])\n",
        "    # Appendo le 3 metriche alle relative liste\n",
        "    k_fold_accuracies.append(accuratezza)\n",
        "    k_fold_precisions_ClassOK.append(precisione_OK)\n",
        "    # Stampo le metriche\n",
        "    print(\"Accurezza a k = \" + str(i) + \":\" + str(accuratezza))\n",
        "    print(\"Precisione classe OK a k = \" + str(i) + \": \" + str(k_fold_precisions_ClassOK))\n",
        "    print(\"\")\n",
        "    \n",
        "  if i == 1: \n",
        "    confusion_matrix1 = confusion_matrix(y_test_3_labels, predizione_labels, labels=[0, 1, 2])\n",
        "    k_fold_conf_matrix.append(confusion_matrix1)\n",
        "    print(\"Matrice di confusione\")\n",
        "    print(confusion_matrix1)\n",
        "    accuratezza = (confusion_matrix1[0][0] + confusion_matrix1[1][1] + confusion_matrix1[2][2])/(len(y_test_3_labels))\n",
        "    precisione_OK = (confusion_matrix1[0][0])/(confusion_matrix1[0][0] + confusion_matrix1[0][1] + confusion_matrix1[0][2])\n",
        "    k_fold_accuracies.append(accuratezza)\n",
        "    k_fold_precisions_ClassOK.append(precisione_OK)\n",
        "    print(\"Accurezza a k = \" + str(i) + \": \" + str(accuratezza))\n",
        "    print(\"Precisione classe OK a k = \" + str(i) + \": \" + str(k_fold_precisions_ClassOK))\n",
        "    print(\"\")\n",
        "\n",
        "  if i == 2: \n",
        "    confusion_matrix2 = confusion_matrix(y_test_3_labels, predizione_labels, labels=[0, 1, 2])\n",
        "    k_fold_conf_matrix.append(confusion_matrix2)\n",
        "    print(\"Matrice di confusione\")\n",
        "    print(confusion_matrix2)\n",
        "    accuratezza = (confusion_matrix2[0][0] + confusion_matrix2[1][1] + confusion_matrix2[2][2])/(len(y_test_3_labels))\n",
        "    precisione_OK = (confusion_matrix2[0][0])/(confusion_matrix2[0][0] + confusion_matrix2[0][1] + confusion_matrix2[0][2])\n",
        "    k_fold_accuracies.append(accuratezza)\n",
        "    k_fold_precisions_ClassOK.append(precisione_OK)\n",
        "    print(\"Accurezza a k = \" + str(i) + \": \" + str(accuratezza))\n",
        "    print(\"Precisione classe OK a k = \" + str(i) + \": \" + str(k_fold_precisions_ClassOK))\n",
        "    print(\"\")\n",
        "    print(\"Vettore y_train\")\n",
        "    print(y_train_3)\n",
        "    print(\"Vettore y_validation\")\n",
        "    print(y_validation_3)\n",
        "    print(\"Vettore y_test\")\n",
        "    print(y_test_3)\n",
        "    print(\"\")\n",
        "\n",
        "  if i == 3: \n",
        "    confusion_matrix3 = confusion_matrix(y_test_3_labels, predizione_labels, labels=[0, 1, 2])\n",
        "    k_fold_conf_matrix.append(confusion_matrix3)\n",
        "    print(\"Matrice di confusione\")\n",
        "    print(confusion_matrix3)\n",
        "    accuratezza = (confusion_matrix3[0][0] + confusion_matrix3[1][1] + confusion_matrix3[2][2])/(len(y_test_3_labels))\n",
        "    precisione_OK = (confusion_matrix3[0][0])/(confusion_matrix3[0][0] + confusion_matrix3[0][1] + confusion_matrix3[0][2])\n",
        "    k_fold_accuracies.append(accuratezza)\n",
        "    k_fold_precisions_ClassOK.append(precisione_OK)\n",
        "    print(\"Accurezza a k = \" + str(i) + \": \" + str(accuratezza))\n",
        "    print(\"Precisione classe OK a k = \" + str(i) + \": \" + str(k_fold_precisions_ClassOK))\n",
        "    print(\"\")\n",
        "\n",
        "  if i == 4: \n",
        "    confusion_matrix4 = confusion_matrix(y_test_3_labels, predizione_labels, labels=[0, 1, 2])\n",
        "    k_fold_conf_matrix.append(confusion_matrix4)\n",
        "    print(\"Matrice di confusione\")\n",
        "    print(confusion_matrix4)\n",
        "    accuratezza = (confusion_matrix4[0][0] + confusion_matrix4[1][1] + confusion_matrix4[2][2])/(len(y_test_3_labels))\n",
        "    precisione_OK = (confusion_matrix4[0][0])/(confusion_matrix4[0][0] + confusion_matrix4[0][1] + confusion_matrix4[0][2])\n",
        "    k_fold_accuracies.append(accuratezza)\n",
        "    k_fold_precisions_ClassOK.append(precisione_OK)\n",
        "    print(\"Accurezza a k = \" + str(i) + \": \" + str(accuratezza))\n",
        "    print(\"Precisione classe OK a k = \" + str(i) + \": \" + str(k_fold_precisions_ClassOK))\n",
        "    print(\"\")\n",
        "    \n",
        "# FINE CROSS VALIDATION ########################################################\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd898fcc3b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;31m#Assegno i subset generati ai vettore di training, validation e test a seconda del ciclo k a cui mi trovo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# test=0; validation=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_subs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_subs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_subs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 't_subs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predizione_cutoff_no_labels)"
      ],
      "metadata": {
        "id": "AqKe73bbG4Tv",
        "outputId": "b48d3df9-530f-4fd5-d95b-18c239814b00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [0, 1, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [1, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matrice di confusione con k = 0\")\n",
        "print(k_fold_conf_matrix[0])\n",
        "print(\"Accuratezza 'K=0': \" + str(k_fold_accuracies[0]))\n",
        "print(\"Precisione 'K=0': \" + str(k_fold_precisions_ClassOK[0]))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Matrice di confusione con k = 1\")\n",
        "print(k_fold_conf_matrix[1])\n",
        "print(\"Accuratezza 'K=1': \" + str(k_fold_accuracies[1]))\n",
        "print(\"Precisione 'K=1': \" + str(k_fold_precisions_ClassOK[1]))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Matrice di confusione con k = 2\")\n",
        "print(k_fold_conf_matrix[2])\n",
        "print(\"Accuratezza 'K=2': \" + str(k_fold_accuracies[2]))\n",
        "print(\"Precisione 'K=2': \" + str(k_fold_precisions_ClassOK[2]))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Matrice di confusione con k = 3\")\n",
        "print(k_fold_conf_matrix[3])\n",
        "print(\"Accuratezza 'K=3': \" + str(k_fold_accuracies[3]))\n",
        "print(\"Precisione 'K=3': \" + str(k_fold_precisions_ClassOK[3]))\n",
        "print(\"\")\n",
        "\n",
        "print(\"Matrice di confusione con k = 4\")\n",
        "print(k_fold_conf_matrix[4])\n",
        "print(\"Accuratezza 'K=4': \" + str(k_fold_accuracies[4]))\n",
        "print(\"Precisione 'K=4': \" + str(k_fold_precisions_ClassOK[4]))\n",
        "print(\"\")\n",
        "\n",
        "accuratezza_macro = (k_fold_accuracies[0] + k_fold_accuracies[1] + k_fold_accuracies[2] + k_fold_accuracies[3] + k_fold_accuracies[4])/5\n",
        "precisione_macro = (k_fold_precisions_ClassOK[0] + k_fold_precisions_ClassOK[1] + k_fold_precisions_ClassOK[2] + k_fold_precisions_ClassOK[3] + k_fold_precisions_ClassOK[4])/5\n",
        "\n",
        "micro_conf_matrix = []\n",
        "micro_conf_matrix = k_fold_conf_matrix[0] + k_fold_conf_matrix[1] + k_fold_conf_matrix[2] + k_fold_conf_matrix[3] + k_fold_conf_matrix[4]\n",
        "\n",
        "denominatore_micro = 0\n",
        "\n",
        "for i in range (0,3):\n",
        "  for j in range(0,3): \n",
        "    denominatore_micro = denominatore_micro + micro_conf_matrix[i][j]\n",
        "\n",
        "accuratezza_micro = (micro_conf_matrix[0][0] + micro_conf_matrix[1][1] + micro_conf_matrix[2][2])/denominatore_micro\n",
        "precisione_micro = (micro_conf_matrix[0][0])/(micro_conf_matrix[0][0] + micro_conf_matrix[0][1] + micro_conf_matrix[0][2])\n",
        "\n",
        "print(\"Accuratezza macro: \" + str(accuratezza_macro))\n",
        "print(\"Accuratezza micro: \" + str(accuratezza_micro))\n",
        "print(\"\")\n",
        "print(\"Precisione OK macro: \" + str(precisione_macro))\n",
        "print(\"Precisione OK micro: \" + str(precisione_micro))\n"
      ],
      "metadata": {
        "id": "0vCTzT_QjyaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcolo precisione per classe rOK \n",
        "# Calcolo il bilancio dei falsi positivi. Il sistema può essere tollerante a un \n",
        "# paraolio dritto classificato come rovescio ma non il contrario.\n",
        "\n",
        "# K-Fold = 0\n",
        "precisione_rOK0 = (confusion_matrix0[1][1])/(confusion_matrix0[1][0] + confusion_matrix0[1][2])\n",
        "false_pos_rate_rOK0 = (confusion_matrix0[1][0] + confusion_matrix0[1][2])/(confusion_matrix0[1][0] + confusion_matrix0[1][2] + confusion_matrix0[0][0] + confusion_matrix0[2][2])\n",
        "print('Matrice di confusione con k = 0')\n",
        "print(confusion_matrix0)\n",
        "print('Precisione rOK k = 0: ', precisione_rOK)\n",
        "print('False Positive rate k = 0: ', false_pos_rate_rOK)\n",
        "\n",
        "# K-Fold = 1\n",
        "precisione_rOK1 = (confusion_matrix1[1][1])/(confusion_matrix1[1][0] + confusion_matrix1[1][2])\n",
        "false_pos_rate_rOK1 = (confusion_matrix1[1][0] + confusion_matrix1[1][2])/(confusion_matrix1[1][0] + confusion_matrix1[1][2] + confusion_matrix1[0][0] + confusion_matrix1[2][2])\n",
        "print('Matrice di confusione con k = 1')\n",
        "print(confusion_matrix1)\n",
        "print('Precisione rOK k = 1: ', precisione_rOK1)\n",
        "print('False Positive rate k = 1: ', false_pos_rate_rOK1)\n",
        "\n",
        "# K-Fold = 2\n",
        "precisione_rOK2 = (confusion_matrix2[1][1])/(confusion_matrix2[1][0] + confusion_matrix2[1][2])\n",
        "false_pos_rate_rOK2 = (confusion_matrix2[1][0] + confusion_matrix2[1][2])/(confusion_matrix2[1][0] + confusion_matrix2[1][2] + confusion_matrix2[0][0] + confusion_matrix2[2][2])\n",
        "print('Matrice di confusione k = 2')\n",
        "print(confusion_matrix2)\n",
        "print('Precisione rOK k = 2: ',precisione_rOK2)\n",
        "print('False Positive rate k = 2: ', false_pos_rate_rOK2)\n",
        "\n",
        "# K-Fold = 3\n",
        "precisione_rOK3 = (confusion_matrix3[1][1])/(confusion_matrix3[1][0] + confusion_matrix3[1][2])\n",
        "false_pos_rate_rOK3 = (confusion_matrix3[1][0] + confusion_matrix3[1][2])/(confusion_matrix3[1][0] + confusion_matrix3[1][2] + confusion_matrix3[0][0] + confusion_matrix3[2][2])\n",
        "print('Matrice di confusione k = 3')\n",
        "print(confusion_matrix3)\n",
        "print('Precisione rOK k = 3: ',precisione_rOK3)\n",
        "print('False Positive rate k = 3: ', false_pos_rate_rOK3)\n",
        "\n",
        "# K-Fold = 4\n",
        "precisione_rOK4 = (confusion_matrix4[1][1])/(confusion_matrix4[1][0] + confusion_matrix4[1][2])\n",
        "false_pos_rate_rOK4 = (confusion_matrix4[1][0] + confusion_matrix4[1][2])/(confusion_matrix4[1][0] + confusion_matrix4[1][2] + confusion_matrix4[0][0] + confusion_matrix4[2][2])\n",
        "print('Matrice di confusione k = 4')\n",
        "print(confusion_matrix4)\n",
        "print('Precisione rOK k = 4: ',precisione_rOK4)\n",
        "print('False Positive rate k = 4: ', false_pos_rate_rOK4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl6B7iS3wwWC",
        "outputId": "60aa7d2b-0040-46e1-cc45-7cf5515b36fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrice di confusione con k = 0\n",
            "[[24  0  3]\n",
            " [ 0 30  0]\n",
            " [ 1  0 42]]\n",
            "Precisione rOK k = 0:  inf\n",
            "False Positive rate k = 0:  0.0\n",
            "Matrice di confusione con k = 1\n",
            "[[27  0  0]\n",
            " [ 0 29  0]\n",
            " [ 0  0 44]]\n",
            "Precisione rOK k = 1:  inf\n",
            "False Positive rate k = 1:  0.0\n",
            "Matrice di confusione k = 2\n",
            "[[ 0  0 28]\n",
            " [ 0  0 36]\n",
            " [ 0  0 36]]\n",
            "Precisione rOK k = 2:  0.0\n",
            "False Positive rate k = 2:  0.5\n",
            "Matrice di confusione k = 3\n",
            "[[30  0  1]\n",
            " [ 0 26  0]\n",
            " [ 0  0 43]]\n",
            "Precisione rOK k = 3:  inf\n",
            "False Positive rate k = 3:  0.0\n",
            "Matrice di confusione k = 4\n",
            "[[36  0  1]\n",
            " [ 0 29  0]\n",
            " [ 0  0 35]]\n",
            "Precisione rOK k = 4:  inf\n",
            "False Positive rate k = 4:  0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in long_scalars\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in long_scalars\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in long_scalars\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: divide by zero encountered in long_scalars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IA6mBxry5Eh4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}